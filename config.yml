database:
  # SQLAlchemy database URL. For SQLite, path is relative to project root.
  url: "sqlite:///data/lean_explore_data.db"

llm:
  openai_base_url: "https://openrouter.ai/api/v1"
  # --- Model Configuration ---
  # Model for text generation.
  generation_model: "deepseek/deepseek-chat-v3.1"
  # Google Gemini model for API-based text embeddings.
  # Note: Search uses a local sentence-transformer model specified in 'search' section.
  embedding_model: "models/text-embedding-004"

  # --- API Call Behavior ---
  # Max retries for failed Gemini API calls.
  retries: 3
  # Base factor (seconds) for exponential backoff between retries.
  backoff: 1.0
  # Token budget for model's internal "thinking" (model-dependent).
  thinking_budget: 0 # Example, adjust based on model specifics

lean_to_english:
  # --- Prompt Construction Limits ---
  # Max char length for individual dependency descriptions in prompts.
  max_dependency_description_length: 1000
  # Max number of dependency descriptions to include in prompts.
  max_dependencies_in_prompt: 50
  # Total char budget for the entire prerequisite context in prompts.
  total_prerequisite_context_char_limit: 15000

  # --- Processing Configuration ---
  # Max concurrent LLM API calls for processing declarations.
  max_concurrent_llm_calls: 100
  # Max number of entries to gather from DB at once for processing.
  max_gather_batch_size: 10000
  # Filename of the prompt template (in project root or src).
  prompt_template_filename: "src/prompt_template.txt"

get_summaries:
  # Default database URL for the get_summaries script.
  database_url: "sqlite:///data/lean_explore_data.db"
  # Path to the prompt template file for summary generation.
  prompt_template_path: "scripts/summary_prompt_template.txt"
  # Max concurrent LLM API calls for generating summaries.
  max_concurrent_llm_calls: 20
  # Max number of entries to gather for LLM processing at once.
  max_gather_batch_size: 100

search:
  # --- Semantic Search ---
  # Sentence-transformer model for query embeddings (must match FAISS index model).
  embedding_model_name: "Qwen/Qwen3-Embedding-0.6B"
  # Path to FAISS index file (relative to project root).
  faiss_index_path: "data/main_faiss.index"
  # Path to FAISS ID map file (relative to project root).
  faiss_map_path: "data/faiss_ids_map.json"
  # Initial number of nearest neighbors from FAISS (k).
  faiss_k: 100
  # For IVF-type FAISS indexes, number of closest cells/clusters to search.
  faiss_nprobe: 200
  # Factor to multiply faiss_k by when package filters are active, to increase initial candidate pool.
  faiss_oversampling_factor_for_packages: 3
  # Minimum raw semantic similarity score [0,1] for a result to be considered.
  semantic_similarity_threshold: 0.525

  # --- Ranking Weights ---
  # Weight for PageRank score (graph centrality).
  pagerank_weight: 0.2
  # Weight for semantic similarity score (query relevance).
  text_relevance_weight: 1.0
  # Name match weight
  name_match_weight: 1.0

  # --- Output ---
  # Default number of final results to display.
  results_limit: 50